{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a0b4cc1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42bb7a54",
   "metadata": {},
   "source": [
    "## Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b9eb1b42",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./data/Dry_Bean_Dataset.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3903e07a",
   "metadata": {},
   "source": [
    "## Data Description"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acf06dd1",
   "metadata": {},
   "source": [
    "padndas prfiling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "877655a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\abina\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\ydata_profiling\\profile_report.py:354: UserWarning: Try running command: 'pip install --upgrade Pillow' to avoid ValueError\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dbd8ef0821b949ec94be7eb76b820df8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Summarize dataset:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\abina\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\ydata_profiling\\model\\correlations.py:66: UserWarning: There was an attempt to calculate the auto correlation, but this failed.\n",
      "To hide this warning, disable the calculation\n",
      "(using `df.profile_report(correlations={\"auto\": {\"calculate\": False}})`\n",
      "If this is problematic for your use case, please report this as an issue:\n",
      "https://github.com/ydataai/ydata-profiling/issues\n",
      "(include the error message: 'could not convert string to float: 'SEKER'')\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# import matplotlib\n",
    "# from ydata_profiling import ProfileReport\n",
    "# profile = ProfileReport(df, title=\"Profiling Report\")\n",
    "# profile.to_file(\"pandasprofinng_output.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69bca757",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18c7b252",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0e3eb20",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Class\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6a6f9b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "837bbf06",
   "metadata": {},
   "source": [
    "## Data cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01f743fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72fb41e2",
   "metadata": {},
   "source": [
    "No missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e7cdffd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faf07f5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_counts = df[\"Class\"].value_counts()\n",
    "print(class_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03947a59",
   "metadata": {},
   "source": [
    "# EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7920e16d",
   "metadata": {},
   "outputs": [],
   "source": [
    "indicators = df.columns[:-1]\n",
    "df.plot(x = \"Class\", y = indicators, subplots = True, layout = (4, 4),\n",
    "       figsize = (16, 16), sharex = False, rot = 90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bf74eff",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_classes = df.Class.unique()\n",
    "def draw_conditional_distribution(ax, df, col):\n",
    "    bins = np.linspace(df[col].min(), df[col].max(), 50)\n",
    "    for cls in unique_classes:\n",
    "        ax.hist(df[df.Class == cls][col], alpha=0.5, label=cls, bins=bins)\n",
    "    ax.set_title(f'Distributions for {col}')\n",
    "    ax.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57c0ed08",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(len(df.drop('Class', axis=1).columns) // 4, 4, figsize=(15, 15))\n",
    "for idx, col in enumerate(df.drop('Class', axis=1).columns):\n",
    "    draw_conditional_distribution(ax[idx // 4, idx % 4], df, col)\n",
    "plt.suptitle('Distributions for all features, conditional on target')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8552791d",
   "metadata": {},
   "source": [
    "Here you can immediately notice that the Bombay class is very different from the others. These grains are much larger than the others. There are very many features where we can separate objects of this class from objects of another with a probability very close to 1.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d51c634e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check outlier of Dry Bean features\n",
    "plt.figure(figsize = (10, 5))\n",
    "sns.boxplot(df[indicators])\n",
    "plt.title(\"Boxplot of Dry Bean\")\n",
    "plt.xticks(rotation = 90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9e8c02c",
   "metadata": {},
   "outputs": [],
   "source": [
    "removed = df[(df[\"Area\"] >= 100000) & (df[\"ConvexArea\"] >= 100000)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0871d43",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_counts = removed[\"Class\"].value_counts()\n",
    "print(class_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cced7da4",
   "metadata": {},
   "source": [
    "All the instaces from bombay category are outliers also, so we will not consider bobbay class any more"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e90b5f0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete outlier of \"Area\" & \"ConvexArea\"\n",
    "df = df[(df[\"Area\"] < 100000) | (df[\"ConvexArea\"] < 100000)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87da5a7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check outlier of Dry Bean features\n",
    "plt.figure(figsize = (10, 5))\n",
    "sns.boxplot(df[indicators])\n",
    "plt.title(\"Boxplot of Dry Bean\")\n",
    "plt.xticks(rotation = 90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8525fbd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.shape)\n",
    "print(df[\"Class\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ca448e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_scatterplot(ax, col1, col2, df):\n",
    "    unique_labels = df.Class.unique()\n",
    "    for cls in unique_labels:\n",
    "        filtered = df[df.Class == cls]\n",
    "        ax.scatter(filtered[col1], filtered[col2], label=cls, alpha=0.2)\n",
    "    ax.legend()\n",
    "    ax.set_xlabel(col1)\n",
    "    ax.set_ylabel(col2)\n",
    "    ax.set_title(f'Joint scatterplot: {col1} & {col2}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b36b59d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(3, 3, figsize=(15, 15))\n",
    "pairs = [('Area', 'Eccentricity'), ('Eccentricity', 'Solidity'), ('Area', 'EquivDiameter'), ('roundness', 'Compactness'),\n",
    "         ('ShapeFactor1', 'ShapeFactor2'), ('ShapeFactor2', 'ShapeFactor3'), ('ShapeFactor3', 'ShapeFactor4'), ('Compactness', 'Solidity'),\n",
    "         ('Area', 'Solidity')]\n",
    "for idx, p in enumerate(pairs):\n",
    "    draw_scatterplot(ax[idx // 3, idx % 3], *p, df)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bacbd320",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import seaborn as sns\n",
    "plt.figure(figsize = (16, 16))\n",
    "for i, col in enumerate(indicators, 1):\n",
    "    plt.subplot(4, 4, i)\n",
    "    sns.histplot(df[col], kde= True)\n",
    "    plt.title(f\"Distribution of {col} Data\")\n",
    "    plt.tight_layout()\n",
    "    plt.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d56ead76",
   "metadata": {},
   "source": [
    "Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10883c71",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "# Correlation of Dry Bran with Class\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "df[\"Class\"] = le.fit_transform(df[\"Class\"])\n",
    "df_corr = df.corr()\n",
    "df_corr[\"Class\"].sort_values(ascending = False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d3a2d59",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (10, 10))\n",
    "sns.heatmap(df_corr, cmap = 'RdPu', annot = True, fmt = \".2f\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1422170",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split Train/Test\n",
    "X = df.iloc[:,:-1]\n",
    "y = df.iloc[:, -1]\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07d4bd34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Scaling\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "X_train_sc = sc.fit_transform(X_train)\n",
    "X_test_sc = sc.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b18a848d",
   "metadata": {},
   "source": [
    "Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83832c78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LogisticRegressor - Not Scaled\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "lr = LogisticRegression()\n",
    "lr.fit(X_train, y_train)\n",
    "y_lr = lr.predict(X_test)\n",
    "\n",
    "# Model Score\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "print(\"Normal Score :\", lr.score(X_test, y_test))\n",
    "print(\"Mean Absolute Error :\", mean_absolute_error(y_test, y_lr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02612f3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LogisticRegressor - Scaled\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "lr = LogisticRegression()\n",
    "lr.fit(X_train_sc, y_train)\n",
    "y_lr = lr.predict(X_test_sc)\n",
    "\n",
    "# Model Score\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "print(\"Normal Score :\", lr.score(X_test_sc, y_test))\n",
    "print(\"Mean Absolute Error :\", mean_absolute_error(y_test, y_lr))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23907665",
   "metadata": {},
   "source": [
    "Random Forest Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6683138",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RandomForestRegressor - Not Scaled\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "rfr = RandomForestRegressor()\n",
    "rfr.fit(X_train, y_train)\n",
    "y_rfr = rfr.predict(X_test)\n",
    "\n",
    "# Model Score\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "print(\"Normal Score :\", rfr.score(X_test, y_test))\n",
    "print(\"Mean Absolute Error :\", mean_absolute_error(y_test, y_rfr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "853d9260",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RandomForestRegressor - Scaled\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "rfr = RandomForestRegressor()\n",
    "rfr.fit(X_train_sc, y_train)\n",
    "y_rfr = rfr.predict(X_test_sc)\n",
    "\n",
    "# Model Score\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "print(\"Normal Score :\", rfr.score(X_test_sc, y_test))\n",
    "print(\"Mean Absolute Error :\", mean_absolute_error(y_test, y_rfr))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "970973f8",
   "metadata": {},
   "source": [
    "Decision Tree Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fdb5d11",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# Create Decision Tree Classifier - not scaled\n",
    "dt_classifier = DecisionTreeClassifier()\n",
    "\n",
    "# Train Decision Tree Classifier\n",
    "dt_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Predict using Decision Tree Classifier\n",
    "y_dt = dt_classifier.predict(X_test)\n",
    "\n",
    "# Model Score\n",
    "print(\"Decision Tree Classifier Score:\", dt_classifier.score(X_test, y_test))\n",
    "\n",
    "# Mean Absolute Error\n",
    "print(\"Mean Absolute Error:\", mean_absolute_error(y_test, y_dt))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da51c0b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Decision Tree Classifier - scaled\n",
    "dt_classifier = DecisionTreeClassifier()\n",
    "\n",
    "# Train Decision Tree Classifier\n",
    "dt_classifier.fit(X_train_sc, y_train)\n",
    "\n",
    "# Predict using Decision Tree Classifier\n",
    "y_dt = dt_classifier.predict(X_test_sc)\n",
    "\n",
    "# Model Score\n",
    "print(\"Decision Tree Classifier Score:\", dt_classifier.score(X_test_sc, y_test))\n",
    "\n",
    "# Mean Absolute Error\n",
    "print(\"Mean Absolute Error:\", mean_absolute_error(y_test, y_dt))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18fc8e53",
   "metadata": {},
   "source": [
    "SVM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54a160da",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "# Create SVM Classifier\n",
    "svm_classifier = SVC()\n",
    "\n",
    "# Train SVM Classifier Not\n",
    "svm_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Predict using SVM Classifier\n",
    "y_svm = svm_classifier.predict(X_test)\n",
    "\n",
    "# Model Score\n",
    "print(\"SVM Classifier Score:\", svm_classifier.score(X_test, y_test))\n",
    "\n",
    "# Mean Absolute Error\n",
    "print(\"Mean Absolute Error:\", mean_absolute_error(y_test, y_svm))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "675226dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Create SVM Classifier\n",
    "svm_classifier2 = SVC()\n",
    "\n",
    "# Train SVM Classifier scaled\n",
    "svm_classifier2.fit(X_train_sc, y_train)\n",
    "\n",
    "# Predict using SVM Classifier\n",
    "y_svm = svm_classifier2.predict(X_test_sc)\n",
    "\n",
    "# Model Score\n",
    "print(\"SVM Classifier Score:\", svm_classifier2.score(X_test_sc, y_test))\n",
    "\n",
    "# Mean Absolute Error\n",
    "print(\"Mean Absolute Error:\", mean_absolute_error(y_test, y_svm))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9016b098",
   "metadata": {},
   "source": [
    "- Logistic regression with scaling achieved the highest model score of 91.81% and the lowest mean absolute error of 0.203.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29367fb5",
   "metadata": {},
   "source": [
    "Using Kmeans clustering to delete outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9e7dbaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "km = KMeans(n_clusters = 2)\n",
    "km.fit(df[indicators])\n",
    "labels = km.labels_\n",
    "df_km = df[labels == 1]\n",
    "df_km.reset_index(inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ede45d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (10, 5))\n",
    "sns.boxplot(df_km[indicators])\n",
    "plt.title(\"Boxplot of Dry Bean w/o outliers\")\n",
    "plt.xticks(rotation = 90)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38508fc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation of Dry Bran with Class\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "df_km[\"Class\"] = le.fit_transform(df_km[\"Class\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13d89fad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split Train/Test\n",
    "X = df_km.iloc[:,:-1]\n",
    "y = df_km.iloc[:, -1]\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)\n",
    "\n",
    "# Feature Scaling\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "X_train_sc = sc.fit_transform(X_train)\n",
    "X_test_sc = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4f93162",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "\n",
    "\n",
    "\n",
    "# LogisticRegressor - Scaled\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "lr = LogisticRegression()\n",
    "lr.fit(X_train_sc, y_train)\n",
    "y_lr = lr.predict(X_test_sc)\n",
    "\n",
    "# Model Score\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "print(\"Normal Score :\", lr.score(X_test_sc, y_test))\n",
    "print(\"Mean Absolute Error :\", mean_absolute_error(y_test, y_lr))\n",
    "\n",
    "# Precision\n",
    "precision = precision_score(y_test, y_lr, average='macro')\n",
    "print(\"Precision:\", precision)\n",
    "\n",
    "# Recall\n",
    "recall = recall_score(y_test, y_lr, average='macro')\n",
    "print(\"Recall:\", recall)\n",
    "\n",
    "# F1 Score\n",
    "f1 = f1_score(y_test, y_lr, average='macro')\n",
    "print(\"F1 Score:\", f1)\n",
    "\n",
    "# Confusion Matrix\n",
    "conf_matrix = confusion_matrix(y_test, y_lr)\n",
    "print(\"Confusion Matrix:\\n\", conf_matrix)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0272bf4c",
   "metadata": {},
   "source": [
    "Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70486c79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RandomForestRegressor - Scaled\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "rfr = RandomForestRegressor()\n",
    "rfr.fit(X_train_sc, y_train)\n",
    "y_rfr = rfr.predict(X_test_sc)\n",
    "\n",
    "# Model Score\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "print(\"Normal Score :\", rfr.score(X_test_sc, y_test))\n",
    "print(\"Mean Absolute Error :\", mean_absolute_error(y_test, y_rfr))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d194c6cf",
   "metadata": {},
   "source": [
    "Decision Tree Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "735cada4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Decision Tree Classifier - scaled\n",
    "dt_classifier = DecisionTreeClassifier()\n",
    "\n",
    "# Train Decision Tree Classifier\n",
    "dt_classifier.fit(X_train_sc, y_train)\n",
    "\n",
    "# Predict using Decision Tree Classifier\n",
    "y_dt = dt_classifier.predict(X_test_sc)\n",
    "\n",
    "# Model Score\n",
    "print(\"Decision Tree Classifier Score:\", dt_classifier.score(X_test_sc, y_test))\n",
    "\n",
    "# Mean Absolute Error\n",
    "print(\"Mean Absolute Error:\", mean_absolute_error(y_test, y_dt))\n",
    "\n",
    "\n",
    "# Precision\n",
    "precision = precision_score(y_test, y_dt, average='macro')\n",
    "print(\"Precision:\", precision)\n",
    "\n",
    "# Recall\n",
    "recall = recall_score(y_test, y_dt, average='macro')\n",
    "print(\"Recall:\", recall)\n",
    "\n",
    "# F1 Score\n",
    "f1 = f1_score(y_test, y_dt, average='macro')\n",
    "print(\"F1 Score:\", f1)\n",
    "\n",
    "# Confusion Matrix\n",
    "conf_matrix = confusion_matrix(y_test, y_dt)\n",
    "print(\"Confusion Matrix:\\n\", conf_matrix)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c9bf36e",
   "metadata": {},
   "source": [
    "SVM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a5e6ada",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Create SVM Classifier\n",
    "svm_classifier2 = SVC()\n",
    "\n",
    "# Train SVM Classifier scaled\n",
    "svm_classifier2.fit(X_train_sc, y_train)\n",
    "\n",
    "# Predict using SVM Classifier\n",
    "y_svm = svm_classifier2.predict(X_test_sc)\n",
    "\n",
    "# Model Score\n",
    "print(\"SVM Classifier Score:\", svm_classifier2.score(X_test_sc, y_test))\n",
    "\n",
    "# Mean Absolute Error\n",
    "print(\"Mean Absolute Error:\", mean_absolute_error(y_test, y_svm))\n",
    "\n",
    "# Precision\n",
    "precision = precision_score(y_test, y_svm, average='macro')\n",
    "print(\"Precision:\", precision)\n",
    "\n",
    "# Recall\n",
    "recall = recall_score(y_test, y_svm, average='macro')\n",
    "print(\"Recall:\", recall)\n",
    "\n",
    "# F1 Score\n",
    "f1 = f1_score(y_test, y_svm, average='macro')\n",
    "print(\"F1 Score:\", f1)\n",
    "\n",
    "# Confusion Matrix\n",
    "conf_matrix = confusion_matrix(y_test, y_svm)\n",
    "print(\"Confusion Matrix:\\n\", conf_matrix)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "438d5265",
   "metadata": {},
   "source": [
    "- With outliers removed using KMeans clustering, all models showed significantly improved performance.\n",
    "- Decision Tree achieved perfect accuracy and F1 score, indicating it perfectly classified all instances.\n",
    "- Random Forest also performed exceptionally well with a nearly perfect model score and negligible mean absolute error.\n",
    "- Logistic Regression and SVM achieved high accuracy and precision, indicating robust performance in classification.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1633df11",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
